import os
from typing import List
from langchain_community.vectorstores import Chroma
from langchain.docstore.document import Document
from langchain_community.embeddings import HuggingFaceEmbeddings
from dotenv import load_dotenv
import torch

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
HF_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN")
if not HF_TOKEN:
    raise ValueError("âŒ .env íŒŒì¼ì— HUGGINGFACEHUB_API_TOKENì´ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")

# ê²½ë¡œ ì„¤ì •
VECTOR_DB_DIR = "data/vector_db"
EMBEDDING_MODEL_NAME = "BAAI/bge-m3"

class VectorStoreBuilder:
    def __init__(self, persist_directory=VECTOR_DB_DIR):
        self.persist_directory = persist_directory
        self.embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={
                "device": "cuda:0" if torch.cuda.is_available() else "cpu",
                "use_auth_token": HF_TOKEN
            },
            encode_kwargs={"normalize_embeddings": True}
        )
        self.vectorstore = Chroma(
            persist_directory=self.persist_directory,
            embedding_function=self.embedding_model
        )

    def build_from_documents(self, documents: List[Document], overwrite=False):
        if overwrite:
            print("âš ï¸ ê¸°ì¡´ ë²¡í„° ì €ìž¥ì†Œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
            import shutil
            shutil.rmtree(self.persist_directory, ignore_errors=True)
            os.makedirs(self.persist_directory, exist_ok=True)
            self.vectorstore = Chroma(
                persist_directory=self.persist_directory,
                embedding_function=self.embedding_model
            )

        print(f"ðŸ’¾ ë²¡í„° ì €ìž¥ ì¤‘... ì´ ë¬¸ì„œ ìˆ˜: {len(documents)}")
        batch_size = 500  # Chroma ì œí•œì„ ê³ ë ¤í•œ ë°°ì¹˜ í¬ê¸° ì„¤ì •
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i+batch_size]
            self.vectorstore.add_documents(batch)
        self.vectorstore.persist()
        print(f"âœ… ì €ìž¥ ì™„ë£Œ: {self.persist_directory}")

    def load_vectorstore(self):
        return Chroma(
            persist_directory=self.persist_directory,
            embedding_function=self.embedding_model
        )

def list_all_titles(persist_directory="data/vector_db") -> List[str]:
    from langchain_community.vectorstores import Chroma
    from langchain_community.embeddings import HuggingFaceEmbeddings
    import os
    from dotenv import load_dotenv
    load_dotenv()
    HF_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN")
    embedding_model = HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        model_kwargs={"device": "cuda:0" if torch.cuda.is_available() else "cpu", "use_auth_token": HF_TOKEN},
        encode_kwargs={"normalize_embeddings": True}
    )

    vectorstore = Chroma(
        persist_directory=persist_directory,
        embedding_function=embedding_model
    )

    all_metadata = vectorstore.get()["metadatas"]
    unique_titles = sorted(set(
        meta.get("title", "").strip()
        for meta in all_metadata
        if meta.get("title") and meta["title"] != "Unknown"
    ))

    return unique_titles
