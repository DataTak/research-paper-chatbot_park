import os
from typing import List, Optional
import sys
import sqlite3
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.schema import Document
from langchain.vectorstores.base import VectorStoreRetriever
from dotenv import load_dotenv
import torch

# SQLite Î≤ÑÏ†Ñ ÌôïÏù∏ Î∞è ÏóÖÍ∑∏Î†àÏù¥Îìú
if sqlite3.sqlite_version_info < (3, 35, 0):
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

# Load environment variables
load_dotenv()
HF_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN")
VECTOR_DB_DIR = "data/vector_db"
EMBEDDING_MODEL_NAME = "BAAI/bge-m3"

class Retriever:
    def __init__(self):
        self.embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={
                "device": "cuda:0" if torch.cuda.is_available() else "cpu",
                "use_auth_token": HF_TOKEN
            },
            encode_kwargs={"normalize_embeddings": True}
        )
        self.vectorstore = Chroma(
            persist_directory=VECTOR_DB_DIR,
            embedding_function=self.embedding_model
        )

    # Í∏∞Î≥∏ Í≤ÄÏÉâ (Îã®Ïàú Ïú†ÏÇ¨ÎèÑ Í∏∞Î∞ò)
    def query_similar_documents(self, query: str, k: int = 10) -> List[Document]:
        print(f"üîç Ïú†ÏÇ¨ÎèÑ Í∏∞Î∞ò Í≤ÄÏÉâ (Top-{k}) Ïã§Ìñâ Ï§ë...")
        results = self.vectorstore.similarity_search(query, k=k)
        for i, doc in enumerate(results, 1):
            print(f"[{i}] {doc.metadata.get('title', '')} / {doc.metadata.get('citation', '')}")
        return results

    # score Í∏∞Î∞ò ÌïÑÌÑ∞ÎßÅ (Ïú†ÏÇ¨ÎèÑ Ï†êÏàò Í∏∞Ï§Ä Ï†úÍ±∞)
    def query_with_score_threshold(self, query: str, k: int = 20, threshold: float = 0.5) -> List[Document]:
        print(f"üîé Score Threshold Í≤ÄÏÉâ (Top-{k}, threshold ‚â• {threshold})...")
        results_with_scores = self.vectorstore.similarity_search_with_score(query, k=k)
        filtered = []
        for doc, score in results_with_scores:
            if score >= threshold:
                filtered.append(doc)
                print(f"[‚úì] {doc.metadata.get('title', '')} / Score: {score:.4f}")
            else:
                print(f"[‚úó] Skipped low score: {score:.4f}")
        return filtered

    # MMR Í∏∞Î∞ò Îã§ÏñëÏÑ± Ï§ëÏã¨ Í≤ÄÏÉâ
    def query_mmr_documents(self, query: str, k: int = 10, lambda_mult: float = 0.5) -> List[Document]:
        print(f"üß† MMR Í≤ÄÏÉâ Ïã§Ìñâ (Top-{k}, Œª={lambda_mult})...")
        retriever: VectorStoreRetriever = self.vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": k, "lambda_mult": lambda_mult}
        )
        results = retriever.get_relevant_documents(query)
        for i, doc in enumerate(results, 1):
            print(f"[{i}] {doc.metadata.get('title', '')} / {doc.metadata.get('citation', '')}")
        return results

    # ÌÉÄÏù¥ÌãÄ Í∏∞Î∞ò ÌïÑÌÑ∞
    def query_documents_by_title(self, title: str) -> List[Document]:
        print(f"üìÑ Ï†úÎ™©ÏúºÎ°ú Î¨∏ÏÑú ÌïÑÌÑ∞ÎßÅ: {title}")
        all_docs = self.vectorstore.get(include=['documents', 'metadatas'])
        filtered = []
        for i, metadata in enumerate(all_docs["metadatas"]):
            if metadata.get("title", "").strip().lower() == title.strip().lower():
                filtered.append(Document(page_content=all_docs["documents"][i], metadata=metadata))
        print(f"‚úÖ Í≤ÄÏÉâÎêú Î¨∏ÏÑú Ïàò: {len(filtered)}")
        return filtered

    # ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú query Î¶¨ÎùºÏù¥ÌåÖ (Îã®ÏàúÌòï)
    def rewrite_query(self, query: str) -> str:
        return f"Ïù¥ ÏßàÎ¨∏ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ ÏùòÎØ∏Î•º Í∞ÄÏßëÎãàÎã§: {query}. Í¥ÄÎ†® Ïó∞Íµ¨ ÎÖºÎ¨∏Ïù¥ÎÇò ÏÇ¨Î°Ä Ï§ëÏã¨ÏúºÎ°ú Í≤ÄÏÉâÌï¥ Ï£ºÏÑ∏Ïöî."

    # Ï†ÑÏ≤¥ ÌÉÄÏù¥ÌãÄ Î™©Î°ù
    @staticmethod
    def list_all_titles(vector_db_path: str) -> List[str]:
        embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={"device": "cpu", "use_auth_token": HF_TOKEN},
            encode_kwargs={"normalize_embeddings": True}
        )
        db = Chroma(persist_directory=vector_db_path, embedding_function=embedding_model)
        all_docs = db.get(include=["metadatas"])

        seen = set()
        unique_titles = []

        for metadata in all_docs["metadatas"]:
            title = metadata.get("title", "Unknown").strip()
            authors = metadata.get("authors", "").strip()
            year = metadata.get("year", "n.d.")
            key = f"{title}_{authors}"

            if key not in seen:
                seen.add(key)
                unique_titles.append(f'"{title}" ({authors}, {year})')

        return unique_titles
