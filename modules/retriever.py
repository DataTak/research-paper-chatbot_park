import os
from typing import List, Optional
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.schema import Document
from langchain.vectorstores.base import VectorStoreRetriever
from dotenv import load_dotenv
import torch

# Load environment variables
load_dotenv()
HF_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN")
VECTOR_DB_DIR = "data/vector_db"
EMBEDDING_MODEL_NAME = "BAAI/bge-m3"

class Retriever:
    def __init__(self):
        self.embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={
                "device": "cuda:0" if torch.cuda.is_available() else "cpu",
                "use_auth_token": HF_TOKEN
            },
            encode_kwargs={"normalize_embeddings": True}
        )
        self.vectorstore = Chroma(
            persist_directory=VECTOR_DB_DIR,
            embedding_function=self.embedding_model
        )

    # ê¸°ë³¸ ê²€ìƒ‰ (ë‹¨ìˆœ ìœ ì‚¬ë„ ê¸°ë°˜)
    def query_similar_documents(self, query: str, k: int = 10) -> List[Document]:
        print(f"ðŸ” ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ (Top-{k}) ì‹¤í–‰ ì¤‘...")
        results = self.vectorstore.similarity_search(query, k=k)
        for i, doc in enumerate(results, 1):
            print(f"[{i}] {doc.metadata.get('title', '')} / {doc.metadata.get('citation', '')}")
        return results

    # score ê¸°ë°˜ í•„í„°ë§ (ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ì¤€ ì œê±°)
    def query_with_score_threshold(self, query: str, k: int = 20, threshold: float = 0.5) -> List[Document]:
        print(f"ðŸ”Ž Score Threshold ê²€ìƒ‰ (Top-{k}, threshold â‰¥ {threshold})...")
        results_with_scores = self.vectorstore.similarity_search_with_score(query, k=k)
        filtered = []
        for doc, score in results_with_scores:
            if score >= threshold:
                filtered.append(doc)
                print(f"[âœ“] {doc.metadata.get('title', '')} / Score: {score:.4f}")
            else:
                print(f"[âœ—] Skipped low score: {score:.4f}")
        return filtered

    # MMR ê¸°ë°˜ ë‹¤ì–‘ì„± ì¤‘ì‹¬ ê²€ìƒ‰
    def query_mmr_documents(self, query: str, k: int = 10, lambda_mult: float = 0.5) -> List[Document]:
        print(f"ðŸ§  MMR ê²€ìƒ‰ ì‹¤í–‰ (Top-{k}, Î»={lambda_mult})...")
        retriever: VectorStoreRetriever = self.vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": k, "lambda_mult": lambda_mult}
        )
        results = retriever.get_relevant_documents(query)
        for i, doc in enumerate(results, 1):
            print(f"[{i}] {doc.metadata.get('title', '')} / {doc.metadata.get('citation', '')}")
        return results

    # íƒ€ì´í‹€ ê¸°ë°˜ í•„í„°
    def query_documents_by_title(self, title: str) -> List[Document]:
        print(f"ðŸ“„ ì œëª©ìœ¼ë¡œ ë¬¸ì„œ í•„í„°ë§: {title}")
        all_docs = self.vectorstore.get(include=['documents', 'metadatas'])
        filtered = []
        for i, metadata in enumerate(all_docs["metadatas"]):
            if metadata.get("title", "").strip().lower() == title.strip().lower():
                filtered.append(Document(page_content=all_docs["documents"][i], metadata=metadata))
        print(f"âœ… ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(filtered)}")
        return filtered

    # ì‚¬ìš©ìžê°€ ìž…ë ¥í•œ query ë¦¬ë¼ì´íŒ… (ë‹¨ìˆœí˜•)
    def rewrite_query(self, query: str) -> str:
        return f"ì´ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ì€ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤: {query}. ê´€ë ¨ ì—°êµ¬ ë…¼ë¬¸ì´ë‚˜ ì‚¬ë¡€ ì¤‘ì‹¬ìœ¼ë¡œ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”."

    # ì „ì²´ íƒ€ì´í‹€ ëª©ë¡
    @staticmethod
    def list_all_titles(vector_db_path: str) -> List[str]:
        embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={"device": "cpu", "use_auth_token": HF_TOKEN},
            encode_kwargs={"normalize_embeddings": True}
        )
        db = Chroma(persist_directory=vector_db_path, embedding_function=embedding_model)
        all_docs = db.get(include=["metadatas"])

        seen = set()
        unique_titles = []

        for metadata in all_docs["metadatas"]:
            title = metadata.get("title", "Unknown").strip()
            authors = metadata.get("authors", "").strip()
            year = metadata.get("year", "n.d.")
            key = f"{title}_{authors}"

            if key not in seen:
                seen.add(key)
                unique_titles.append(f'"{title}" ({authors}, {year})')

        return unique_titles
