import os
from typing import List, Optional
import sys
import sqlite3
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.schema import Document
from langchain.vectorstores.base import VectorStoreRetriever
from dotenv import load_dotenv
import torch

# SQLite ë²„ì „ í™•ì¸ ë° ì—…ê·¸ë ˆì´ë“œ
if sqlite3.sqlite_version_info < (3, 35, 0):
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

# Load environment variables
load_dotenv()
HF_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN")
VECTOR_DB_DIR = "data/temp_vector_db"
EMBEDDING_MODEL_NAME = "BAAI/bge-m3"

class Retriever:
    def __init__(self):
        self.embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={
                "device": "cpu",
                "use_auth_token": HF_TOKEN
            },
            encode_kwargs={"normalize_embeddings": True}
        )
        self.vectorstore = Chroma(
            persist_directory=VECTOR_DB_DIR,
            embedding_function=self.embedding_model
        )

    # ê¸°ë³¸ ê²€ìƒ‰ (ë‹¨ìˆœ ìœ ì‚¬ë„ ê¸°ë°˜)
    def query_similar_documents(self, query: str, k: int = 10) -> List[Document]:
        print(f"ğŸ” ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ (Top-{k}) ì‹¤í–‰ ì¤‘...")
        results = self.vectorstore.similarity_search(query, k=k)
        for i, doc in enumerate(results, 1):
            print(f"[{i}] {doc.metadata.get('title', '')} / {doc.metadata.get('citation', '')}")
        return results

    # score ê¸°ë°˜ í•„í„°ë§ (ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ì¤€ ì œê±°)
    def query_with_score_threshold(self, query: str, k: int = 20, threshold: float = 0.5) -> List[Document]:
        print(f"ğŸ” Score Threshold ê²€ìƒ‰ (Top-{k}, threshold â‰¥ {threshold})...")
        results_with_scores = self.vectorstore.similarity_search_with_score(query, k=k)
        filtered = []
        for doc, score in results_with_scores:
            if score >= threshold:
                filtered.append(doc)
                print(f"[âœ“] {doc.metadata.get('title', '')} / Score: {score:.4f}")
            else:
                print(f"[âœ—] Skipped low score: {score:.4f}")
        return filtered

    # MMR ê¸°ë°˜ ë‹¤ì–‘ì„± ì¤‘ì‹¬ ê²€ìƒ‰
    def query_mmr_documents(self, query: str, k: int = 10, lambda_mult: float = 0.5) -> List[Document]:
        print(f"ğŸ§  MMR ê²€ìƒ‰ ì‹¤í–‰ (Top-{k}, Î»={lambda_mult})...")
        retriever: VectorStoreRetriever = self.vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": k, "lambda_mult": lambda_mult}
        )
        results = retriever.get_relevant_documents(query)
        for i, doc in enumerate(results, 1):
            print(f"[{i}] {doc.metadata.get('title', '')} / {doc.metadata.get('citation', '')}")
        return results

    # íƒ€ì´í‹€ ê¸°ë°˜ í•„í„°
    def query_documents_by_title(self, title: str) -> List[Document]:
        print(f"ğŸ“„ ì œëª©ìœ¼ë¡œ ë¬¸ì„œ í•„í„°ë§: {title}")
        all_docs = self.vectorstore.get(include=['documents', 'metadatas'])
        filtered = []
        for i, metadata in enumerate(all_docs["metadatas"]):
            if metadata.get("title", "").strip().lower() == title.strip().lower():
                filtered.append(Document(page_content=all_docs["documents"][i], metadata=metadata))
        print(f"âœ… ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(filtered)}")
        return filtered

    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ query ë¦¬ë¼ì´íŒ… (ë‹¨ìˆœí˜•)
    def rewrite_query(self, query: str) -> str:
        return f"ì´ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ì€ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤: {query}. ê´€ë ¨ ì—°êµ¬ ë…¼ë¬¸ì´ë‚˜ ì‚¬ë¡€ ì¤‘ì‹¬ìœ¼ë¡œ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”."

    # ì „ì²´ íƒ€ì´í‹€ ëª©ë¡
    def list_all_titles(self) -> List[str]:
        """ë²¡í„° DBì—ì„œ ëª¨ë“  ë…¼ë¬¸ ì œëª©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            all_docs = self.vectorstore.get(include=["metadatas"])
            
            seen = set()
            unique_titles = []

            for metadata in all_docs["metadatas"]:
                title = metadata.get("title", "Unknown").strip()
                authors = metadata.get("authors", "").strip()
                year = metadata.get("year", "n.d.")
                key = f"{title}_{authors}"

                if key not in seen:
                    seen.add(key)
                    unique_titles.append(f'"{title}" ({authors}, {year})')

            return unique_titles
        except Exception as e:
            print(f"Error in list_all_titles: {str(e)}")
            return []
